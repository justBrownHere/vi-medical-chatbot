{"cells":[{"cell_type":"markdown","metadata":{},"source":["RUN SERVER IN KAGGLE. GPU: T4x2"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T06:37:53.754217Z","iopub.status.busy":"2024-05-15T06:37:53.753903Z","iopub.status.idle":"2024-05-15T06:41:53.869629Z","shell.execute_reply":"2024-05-15T06:41:53.868558Z","shell.execute_reply.started":"2024-05-15T06:37:53.754191Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Retrieving notices: ...working... done\n","Collecting package metadata (current_repodata.json): done\n","Solving environment: done\n","\n","\n","==> WARNING: A newer version of conda exists. <==\n","  current version: 23.7.4\n","  latest version: 24.5.0\n","\n","Please update conda by running\n","\n","    $ conda update -n base -c conda-forge conda\n","\n","Or to minimize the number of packages updated during conda update use\n","\n","     conda install conda=24.5.0\n","\n","\n","\n","## Package Plan ##\n","\n","  environment location: /opt/conda/envs/myenv\n","\n","  added / updated specs:\n","    - python=3.10\n","\n","\n","The following packages will be downloaded:\n","\n","    package                    |            build\n","    ---------------------------|-----------------\n","    _libgcc_mutex-0.1          |      conda_forge           3 KB  conda-forge\n","    bzip2-1.0.8                |       hd590300_5         248 KB  conda-forge\n","    ld_impl_linux-64-2.40      |       h55db66e_0         697 KB  conda-forge\n","    libgcc-ng-13.2.0           |       h77fa898_7         758 KB  conda-forge\n","    libgomp-13.2.0             |       h77fa898_7         412 KB  conda-forge\n","    libsqlite-3.45.3           |       h2797004_0         840 KB  conda-forge\n","    ncurses-6.5                |       h59595ed_0         867 KB  conda-forge\n","    openssl-3.3.0              |       hd590300_0         2.8 MB  conda-forge\n","    pip-24.0                   |     pyhd8ed1ab_0         1.3 MB  conda-forge\n","    python-3.10.14             |hd12c33a_0_cpython        24.3 MB  conda-forge\n","    setuptools-69.5.1          |     pyhd8ed1ab_0         490 KB  conda-forge\n","    tzdata-2024a               |       h0c530f3_0         117 KB  conda-forge\n","    wheel-0.43.0               |     pyhd8ed1ab_1          57 KB  conda-forge\n","    ------------------------------------------------------------\n","                                           Total:        32.8 MB\n","\n","The following NEW packages will be INSTALLED:\n","\n","  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n","  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n","  bzip2              conda-forge/linux-64::bzip2-1.0.8-hd590300_5 \n","  ca-certificates    conda-forge/linux-64::ca-certificates-2024.2.2-hbcca054_0 \n","  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.40-h55db66e_0 \n","  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 \n","  libgcc-ng          conda-forge/linux-64::libgcc-ng-13.2.0-h77fa898_7 \n","  libgomp            conda-forge/linux-64::libgomp-13.2.0-h77fa898_7 \n","  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n","  libsqlite          conda-forge/linux-64::libsqlite-3.45.3-h2797004_0 \n","  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n","  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n","  libzlib            conda-forge/linux-64::libzlib-1.2.13-hd590300_5 \n","  ncurses            conda-forge/linux-64::ncurses-6.5-h59595ed_0 \n","  openssl            conda-forge/linux-64::openssl-3.3.0-hd590300_0 \n","  pip                conda-forge/noarch::pip-24.0-pyhd8ed1ab_0 \n","  python             conda-forge/linux-64::python-3.10.14-hd12c33a_0_cpython \n","  readline           conda-forge/linux-64::readline-8.2-h8228510_1 \n","  setuptools         conda-forge/noarch::setuptools-69.5.1-pyhd8ed1ab_0 \n","  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n","  tzdata             conda-forge/noarch::tzdata-2024a-h0c530f3_0 \n","  wheel              conda-forge/noarch::wheel-0.43.0-pyhd8ed1ab_1 \n","  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0 \n","\n","\n","\n","Downloading and Extracting Packages\n","tzdata-2024a         | 117 KB    |                                       |   0% \n","ld_impl_linux-64-2.4 | 697 KB    |                                       |   0% \u001b[A\n","\n","libgomp-13.2.0       | 412 KB    |                                       |   0% \u001b[A\u001b[A\n","\n","\n","openssl-3.3.0        | 2.8 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n","\n","\n","\n","pip-24.0             | 1.3 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","ncurses-6.5          | 867 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","python-3.10.14       | 24.3 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","libgcc-ng-13.2.0     | 758 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","bzip2-1.0.8          | 248 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","libsqlite-3.45.3     | 840 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","wheel-0.43.0         | 57 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","setuptools-69.5.1    | 490 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","_libgcc_mutex-0.1    | 3 KB      |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","libgomp-13.2.0       | 412 KB    | #4                                    |   4% \u001b[A\u001b[A\n","\n","\n","openssl-3.3.0        | 2.8 MB    | 4                                     |   1% \u001b[A\u001b[A\u001b[A\n","ld_impl_linux-64-2.4 | 697 KB    | 8                                     |   2% \u001b[A\n","\n","\n","\n","tzdata-2024a         | 117 KB    | #####                                 |  14% \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","ncurses-6.5          | 867 KB    | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","python-3.10.14       | 24.3 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","openssl-3.3.0        | 2.8 MB    | ####################9                 |  57% \u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","libgcc-ng-13.2.0     | 758 KB    | 7                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","bzip2-1.0.8          | 248 KB    | ##3                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","libsqlite-3.45.3     | 840 KB    | 7                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","python-3.10.14       | 24.3 MB   | ##2                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","wheel-0.43.0         | 57 KB     | ##########4                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","ld_impl_linux-64-2.4 | 697 KB    | ##################################### | 100% \u001b[A\n","ld_impl_linux-64-2.4 | 697 KB    | ##################################### | 100% \u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","_libgcc_mutex-0.1    | 3 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","setuptools-69.5.1    | 490 KB    | #2                                    |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","libgomp-13.2.0       | 412 KB    | ##################################### | 100% \u001b[A\u001b[A\n","\n","libgomp-13.2.0       | 412 KB    | ##################################### | 100% \u001b[A\u001b[A\n","\n","\n","\n","\n","\n","python-3.10.14       | 24.3 MB   | ####9                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","python-3.10.14       | 24.3 MB   | ########                              |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","python-3.10.14       | 24.3 MB   | ##########9                           |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","python-3.10.14       | 24.3 MB   | #############8                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","python-3.10.14       | 24.3 MB   | ################9                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","python-3.10.14       | 24.3 MB   | ###################8                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","python-3.10.14       | 24.3 MB   | ######################9               |  62% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","python-3.10.14       | 24.3 MB   | #########################8            |  70% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","python-3.10.14       | 24.3 MB   | ############################6         |  78% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","python-3.10.14       | 24.3 MB   | ###############################6      |  86% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","tzdata-2024a         | 117 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","libgcc-ng-13.2.0     | 758 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","libgcc-ng-13.2.0     | 758 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","pip-24.0             | 1.3 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","pip-24.0             | 1.3 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","bzip2-1.0.8          | 248 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","bzip2-1.0.8          | 248 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","libsqlite-3.45.3     | 840 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","libsqlite-3.45.3     | 840 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","wheel-0.43.0         | 57 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","wheel-0.43.0         | 57 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","_libgcc_mutex-0.1    | 3 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","openssl-3.3.0        | 2.8 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n","\n","\n","openssl-3.3.0        | 2.8 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","setuptools-69.5.1    | 490 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","setuptools-69.5.1    | 490 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","ncurses-6.5          | 867 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","ncurses-6.5          | 867 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","                                                                                \u001b[A\n","\n","                                                                                \u001b[A\u001b[A\n","\n","\n","                                                                                \u001b[A\u001b[A\u001b[A\n","\n","\n","\n","                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Preparing transaction: done\n","Verifying transaction: done\n","Executing transaction: done\n","#\n","# To activate this environment, use\n","#\n","#     $ conda activate myenv\n","#\n","# To deactivate an active environment, use\n","#\n","#     $ conda deactivate\n","\n","usage: conda [-h] [--no-plugins] [-V] COMMAND ...\n","conda: error: argument COMMAND: invalid choice: 'activate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'doctor', 'env')\n","Collecting vllm\n","  Downloading vllm-0.4.2-cp310-cp310-manylinux1_x86_64.whl.metadata (9.1 kB)\n","Collecting cmake>=3.21 (from vllm)\n","  Downloading cmake-3.29.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n","Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from vllm) (1.11.1.1)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from vllm) (5.9.3)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from vllm) (0.2.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from vllm) (1.26.4)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from vllm) (2.31.0)\n","Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from vllm) (9.0.0)\n","Collecting transformers>=4.40.0 (from vllm)\n","  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers>=0.19.1 (from vllm)\n","  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from vllm) (0.108.0)\n","Collecting openai (from vllm)\n","  Downloading openai-1.30.1-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: uvicorn[standard] in /opt/conda/lib/python3.10/site-packages (from vllm) (0.25.0)\n","Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from vllm) (2.5.3)\n","Requirement already satisfied: prometheus-client>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from vllm) (0.19.0)\n","Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n","  Downloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl.metadata (13 kB)\n","Collecting tiktoken==0.6.0 (from vllm)\n","  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting lm-format-enforcer==0.9.8 (from vllm)\n","  Downloading lm_format_enforcer-0.9.8-py3-none-any.whl.metadata (14 kB)\n","Collecting outlines==0.0.34 (from vllm)\n","  Downloading outlines-0.0.34-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from vllm) (4.9.0)\n","Requirement already satisfied: filelock>=3.10.4 in /opt/conda/lib/python3.10/site-packages (from vllm) (3.13.1)\n","Requirement already satisfied: ray>=2.9 in /opt/conda/lib/python3.10/site-packages (from vllm) (2.9.0)\n","Requirement already satisfied: nvidia-ml-py in /opt/conda/lib/python3.10/site-packages (from vllm) (11.495.46)\n","Collecting vllm-nccl-cu12<2.19,>=2.18 (from vllm)\n","  Downloading vllm_nccl_cu12-2.18.1.0.4.0.tar.gz (6.2 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting torch==2.3.0 (from vllm)\n","  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n","Collecting xformers==0.0.26.post1 (from vllm)\n","  Downloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Collecting interegular>=0.3.2 (from lm-format-enforcer==0.9.8->vllm)\n","  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from lm-format-enforcer==0.9.8->vllm) (21.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from lm-format-enforcer==0.9.8->vllm) (6.0.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (3.1.2)\n","Collecting lark (from outlines==0.0.34->vllm)\n","  Downloading lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (1.5.8)\n","Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (2.2.1)\n","Collecting diskcache (from outlines==0.0.34->vllm)\n","  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (1.11.4)\n","Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (0.58.1)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (1.4.0)\n","Requirement already satisfied: referencing in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (0.32.1)\n","Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (4.20.0)\n","Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.6.0->vllm) (2023.12.25)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->vllm) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->vllm) (3.2.1)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->vllm) (2024.2.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->vllm)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->vllm)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->vllm)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->vllm)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->vllm)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->vllm)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->vllm)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->vllm)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->vllm)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->vllm)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->vllm)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.3.0 (from torch==2.3.0->vllm)\n","  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->vllm)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: starlette<1.0.0,>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from prometheus-fastapi-instrumentator>=7.0.0->vllm) (0.32.0.post1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->vllm) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->vllm) (2.14.6)\n","Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (8.1.7)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.0.7)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (3.20.3)\n","Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.3.1)\n","Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (2024.2.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.19.1->vllm) (0.22.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->vllm) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->vllm) (4.66.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai->vllm) (4.2.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai->vllm) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai->vllm) (0.27.0)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai->vllm) (1.3.0)\n","Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.14.0)\n","Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (1.0.0)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.19.0)\n","Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.21.0)\n","Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (12.0)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->vllm) (1.2.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->vllm) (1.0.5)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->lm-format-enforcer==0.9.8->vllm) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->outlines==0.0.34->vllm) (2.1.3)\n","Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->outlines==0.0.34->vllm) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->outlines==0.0.34->vllm) (2023.12.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->outlines==0.0.34->vllm) (0.16.2)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->outlines==0.0.34->vllm) (0.41.1)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0->vllm) (1.3.0)\n","Downloading vllm-0.4.2-cp310-cp310-manylinux1_x86_64.whl (67.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading lm_format_enforcer-0.9.8-py3-none-any.whl (40 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading outlines-0.0.34-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading cmake-3.29.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl (19 kB)\n","Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading openai-1.30.1-py3-none-any.whl (320 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n","Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lark-1.1.9-py3-none-any.whl (111 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: vllm-nccl-cu12\n","  Building wheel for vllm-nccl-cu12 (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for vllm-nccl-cu12: filename=vllm_nccl_cu12-2.18.1.0.4.0-py3-none-any.whl size=5419 sha256=50c62b34de31613db298b1f84a52ed92569766ee55863c68d3c8690b50798842\n","  Stored in directory: /root/.cache/pip/wheels/d1/28/b5/e99e6ea84b08c0bf19a218d408316e55e02ff725d3616fb79d\n","Successfully built vllm-nccl-cu12\n","Installing collected packages: vllm-nccl-cu12, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lark, interegular, diskcache, cmake, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, prometheus-fastapi-instrumentator, openai, nvidia-cusolver-cu12, lm-format-enforcer, transformers, torch, xformers, outlines, vllm\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.15.2\n","    Uninstalling tokenizers-0.15.2:\n","      Successfully uninstalled tokenizers-0.15.2\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.39.3\n","    Uninstalling transformers-4.39.3:\n","      Successfully uninstalled transformers-4.39.3\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.2\n","    Uninstalling torch-2.1.2:\n","      Successfully uninstalled torch-2.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cmake-3.29.3 diskcache-5.6.3 interegular-0.3.3 lark-1.1.9 lm-format-enforcer-0.9.8 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 openai-1.30.1 outlines-0.0.34 prometheus-fastapi-instrumentator-7.0.0 tiktoken-0.6.0 tokenizers-0.19.1 torch-2.3.0 transformers-4.40.2 triton-2.3.0 vllm-0.4.2 vllm-nccl-cu12-2.18.1.0.4.0 xformers-0.0.26.post1\n"]}],"source":["!conda create -n myenv python=3.10 -y\n","!conda activate myenv\n","\n","# Install vLLM with CUDA 12.1.\n","!pip install vllm"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T06:43:00.247448Z","iopub.status.busy":"2024-05-15T06:43:00.247057Z","iopub.status.idle":"2024-05-15T06:43:39.845667Z","shell.execute_reply":"2024-05-15T06:43:39.844712Z","shell.execute_reply.started":"2024-05-15T06:43:00.247414Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cubinlinker, which is not installed.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 23.8.0 requires ptxcompiler, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","keras-cv 0.8.2 requires keras-core, which is not installed.\n","keras-nlp 0.9.3 requires keras-core, which is not installed.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n","apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 5.26.1 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\n","cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\n","cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 5.26.1 which is incompatible.\n","cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\n","dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\n","dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\n","dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","distributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\n","fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.3.0 which is incompatible.\n","google-ai-generativelanguage 0.6.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\n","google-cloud-artifact-registry 1.10.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-dlp 3.14.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-language 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-monitoring 2.18.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-pubsub 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-recommendations-ai 0.7.1 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-resource-manager 1.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-spanner 3.40.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-videointelligence 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","google-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 5.26.1 which is incompatible.\n","googleapis-common-protos 1.62.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","grpc-google-iam-v1 0.12.7 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n","jupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n","kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 5.26.1 which is incompatible.\n","kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 5.26.1 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","opentelemetry-proto 1.22.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.26.1 which is incompatible.\n","osmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n","proto-plus 1.23.0 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.26.1 which is incompatible.\n","raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\n","spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 5.26.1 which is incompatible.\n","tensorboard-plugin-profile 2.15.0 requires protobuf<5.0.0dev,>=3.19.6, but you have protobuf 5.26.1 which is incompatible.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\n","tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.26.1 which is incompatible.\n","tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 5.26.1 which is incompatible.\n","tensorflow-serving-api 2.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.26.1 which is incompatible.\n","tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 5.26.1 which is incompatible.\n","wandb 0.16.6 requires protobuf!=4.21.0,<5,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", but you have protobuf 5.26.1 which is incompatible.\n","ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip -qq install -U xformers \n","!pip -qq install langchain optimum qdrant-client wikipedia FastAPI uvicorn pyngrok"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T06:44:03.318565Z","iopub.status.busy":"2024-05-15T06:44:03.317776Z","iopub.status.idle":"2024-05-15T06:44:03.323837Z","shell.execute_reply":"2024-05-15T06:44:03.322816Z","shell.execute_reply.started":"2024-05-15T06:44:03.318528Z"},"trusted":true},"outputs":[],"source":["GENERATE_MODEL_NAME=\"brown1808/vietzephyr-7b-lora-8bit\"\n","EMBEDDINGS_MODEL_NAME=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n","QDRANT_URL = \"<ANT_URL>\"\n","QDRANT_COLLECTION_NAME = \"<QDRANT_COLLECTION_NAME>\"\n","NGROK_STATIC_DOMAIN = \"<NGROK_STATIC_DOMAIN>\"\n","NGROK_TOKEN=          \"<NGROK_TOKEN>\"\n","HUGGINGFACE_API_KEY = \"<HUGGINGFACE_API_KEY>\"\n","QDRANT_API_KEY =      \"<QDRANT_API_KEY>\""]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T06:44:16.811245Z","iopub.status.busy":"2024-05-15T06:44:16.810903Z","iopub.status.idle":"2024-05-15T06:44:40.109321Z","shell.execute_reply":"2024-05-15T06:44:40.108308Z","shell.execute_reply.started":"2024-05-15T06:44:16.811216Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-15 06:44:22.349808: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-15 06:44:22.349933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-15 06:44:22.515110: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5f83f9e945643d5aae6829957518b18","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/696 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f6144f78d044a37b50f10b387405270","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2062f9a6c5344d1bac9531ba48c2d6bc","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f2d4bf8d7c64d8da6c7e76fcaa99b0b","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"530c4a4f4e9a4a75aeca500e0a97fa61","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from optimum.bettertransformer import BetterTransformer\n","import torch\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model_rerank = AutoModelForSequenceClassification.from_pretrained('amberoad/bert-multilingual-passage-reranking-msmarco').to(device)\n","model_rerank = BetterTransformer.transform(model_rerank)\n","tokenizer_rerank = AutoTokenizer.from_pretrained('amberoad/bert-multilingual-passage-reranking-msmarco')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T06:44:43.092667Z","iopub.status.busy":"2024-05-15T06:44:43.092049Z","iopub.status.idle":"2024-05-15T06:44:44.981532Z","shell.execute_reply":"2024-05-15T06:44:44.980550Z","shell.execute_reply.started":"2024-05-15T06:44:43.092637Z"},"trusted":true},"outputs":[],"source":["from langchain.schema.document import Document\n","from langchain_core.vectorstores import VectorStoreRetriever\n","from langchain.retrievers import WikipediaRetriever\n","from typing import List\n","class RerankRetriever(VectorStoreRetriever):\n","    vectorstore: VectorStoreRetriever\n","    def get_relevant_documents(self, query: str) -> List[Document]:\n","        docs = self.vectorstore.get_relevant_documents(query=query)\n","        candidates = [doc.page_content for doc in docs]\n","        queries = [query]*len(candidates)\n","        features = tokenizer_rerank(queries, candidates, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n","        with torch.no_grad():\n","            scores = model_rerank(**features).logits\n","            values, indices = torch.sum(scores, dim=1).sort()\n","            # relevant_docs = docs[indices[0]]\n","        return [docs[indices[0]],docs[indices[1]]]\n","class RerankWikiRetriever(VectorStoreRetriever):\n","    vectorstore: WikipediaRetriever\n","    def get_relevant_documents(self, query: str) -> List[Document]:\n","        docs = self.vectorstore.get_relevant_documents(query=query)\n","        candidates = [doc.page_content for doc in docs]\n","        queries = [query]*len(candidates)\n","        features = tokenizer_rerank(queries, candidates,  padding=True, truncation=True, return_tensors=\"pt\").to(device)\n","        with torch.no_grad():\n","            scores = model_rerank(**features).logits\n","            values, indices = torch.sum(scores, dim=1).sort()\n","            # relevant_docs = docs[indices[0]]\n","        return [docs[indices[0]],docs[indices[1]]]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T06:44:49.082603Z","iopub.status.busy":"2024-05-15T06:44:49.081324Z","iopub.status.idle":"2024-05-15T06:44:51.018279Z","shell.execute_reply":"2024-05-15T06:44:51.017494Z","shell.execute_reply.started":"2024-05-15T06:44:49.082567Z"},"trusted":true},"outputs":[],"source":["from langchain.retrievers import WikipediaRetriever\n","from langchain.vectorstores import Qdrant\n","from langchain.llms import HuggingFacePipeline\n","from qdrant_client import QdrantClient\n","from langchain.prompts import PromptTemplate\n","from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n","from langchain.chains import RetrievalQA,MultiRetrievalQAChain\n","from langchain.llms import VLLM\n","from langchain.llms import HuggingFaceHub\n","\n","class LLMServe:\n","    def __init__(self) -> None:\n","      self.embeddings = self.load_embeddings()\n","      self.current_source = \"wiki\"\n","      self.retriever = self.load_retriever(retriever_name = self.current_source,embeddings=self.embeddings)\n","      self.pipe = self.load_model_pipeline(max_new_tokens=150)\n","      self.prompt = self.load_prompt_template()\n","      self.rag_pipeline = self.load_rag_pipeline(llm=self.pipe,\n","                                            retriever=self.retriever,\n","                                            prompt=self.prompt)\n","    def load_embeddings(self):\n","      embeddings = HuggingFaceInferenceAPIEmbeddings(\n","          model_name=EMBEDDINGS_MODEL_NAME,\n","          api_key = HUGGINGFACE_API_KEY,\n","          model_kwargs = {'device': \"auto\"}\n","      )\n","      return embeddings\n","\n","    def load_retriever(self,retriever_name,embeddings):\n","      retriever=None\n","      if retriever_name == \"wiki\":\n","        retriever = RerankWikiRetriever(vectorstore = WikipediaRetriever(lang=\"vi\",\n","                                       doc_content_chars_max=300,top_k_results=5))\n","      else:\n","        client = QdrantClient(\n","            url=QDRANT_URL,api_key=QDRANT_API_KEY, prefer_grpc=False\n","        )\n","        db = Qdrant(client=client,\n","                    embeddings=embeddings,\n","                    collection_name=QDRANT_COLLECTION_NAME)\n","\n","        retriever = RerankRetriever(vectorstore = db.as_retriever(search_kwargs={\"k\":5}))\n","\n","      return retriever\n","\n","    def load_model_pipeline(self,max_new_tokens=150):\n","      llm = VLLM(\n","          model=GENERATE_MODEL_NAME,\n","          trust_remote_code=True,  # mandatory for hf models\n","          max_new_tokens=max_new_tokens,\n","            # temperature=1.0,\n","            # top_k=50,\n","            # top_p=0.9,\n","          top_k=5,\n","          top_p=0.95,\n","          temperature=0.1,\n","          dtype=\"half\",\n","#           vllm_kwargs={\"quantization\": \"awq\"}\n","\n","      )\n","      return llm\n","\n","    def load_prompt_template(self):\n","      query_template = \"<|im_start|>systemBạn là một trợ lí AI hữu ích. Hãy trả lời người dùng một cách chính xác nhất, nếu thông tin không liên quan đến câu hỏi thì trả lời không biết\\n{context}<|im_end|>\\n<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\"\n","      prompt = PromptTemplate(template=query_template,\n","                        input_variables= [\"context\",\"question\"])\n","      return prompt\n","\n","    def load_rag_pipeline(self,llm,retriever,prompt):\n","      rag_pipeline = RetrievalQA.from_chain_type(\n","      llm=llm, chain_type='stuff',\n","      retriever=retriever,\n","      chain_type_kwargs={\n","      \"prompt\": prompt\n","      },\n","      return_source_documents=True)\n","      return rag_pipeline\n","\n","    def rag(self,source):\n","      if source == self.current_source:\n","        return self.rag_pipeline\n","      else:\n","        self.retriever = self.load_retriever(retriever_name=source,embeddings=self.embeddings)\n","        self.rag_pipeline = self.load_rag_pipeline(llm=self.pipe,\n","                                      retriever=self.retriever,\n","                                      prompt=self.prompt)\n","        self.current_source = source\n","        return self.rag_pipeline"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T06:44:55.697322Z","iopub.status.busy":"2024-05-15T06:44:55.696620Z","iopub.status.idle":"2024-05-15T06:44:57.540765Z","shell.execute_reply":"2024-05-15T06:44:57.539510Z","shell.execute_reply.started":"2024-05-15T06:44:55.697290Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Obtaining file:///kaggle/working\n","\u001b[31mERROR: file:///kaggle/working does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -e ."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T06:45:01.144574Z","iopub.status.busy":"2024-05-15T06:45:01.144201Z","iopub.status.idle":"2024-05-15T06:45:01.148692Z","shell.execute_reply":"2024-05-15T06:45:01.147824Z","shell.execute_reply.started":"2024-05-15T06:45:01.144544Z"},"trusted":true},"outputs":[],"source":["CUDA_LAUNCH_BLOCKING=1,2"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T06:45:03.910997Z","iopub.status.busy":"2024-05-15T06:45:03.910618Z","iopub.status.idle":"2024-05-15T06:45:48.474025Z","shell.execute_reply":"2024-05-15T06:45:48.472985Z","shell.execute_reply.started":"2024-05-15T06:45:03.910968Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-15 06:45:05,315\tINFO util.py:124 -- Outdated packages:\n","  ipywidgets==7.7.1 found, needs ipywidgets>=8\n","Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6e1bd03eeb245e5a4d1593195a6d1ad","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["INFO 05-15 06:45:05 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='brown1808/vinallama-2b-custom-ver2', speculative_config=None, tokenizer='brown1808/vinallama-2b-custom-ver2', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=brown1808/vinallama-2b-custom-ver2)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a87e10d59b9f49389aa63fcd544e7350","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d1b4ba23249419aa2876d720ee9abfe","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.67M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f7e362ee75f4748908bfbd687641257","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/449 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa6a378b310e4f2eb44c605fd685f013","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["INFO 05-15 06:45:06 utils.py:660] Found nccl from library /root/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n","INFO 05-15 06:45:06 selector.py:69] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n","INFO 05-15 06:45:06 selector.py:32] Using XFormers backend.\n","INFO 05-15 06:45:07 weight_utils.py:199] Using model weights format ['*.safetensors']\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56c40ce7538f42e1b3c5767e23a0de5f","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"414556cfc34b4fb88f27917458b8a938","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/554M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["INFO 05-15 06:45:28 model_runner.py:175] Loading model weights took 5.2088 GB\n","INFO 05-15 06:45:30 gpu_executor.py:114] # GPU blocks: 1471, # CPU blocks: 819\n","INFO 05-15 06:45:32 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n","INFO 05-15 06:45:32 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n","INFO 05-15 06:45:48 model_runner.py:1017] Graph capturing finished in 16 secs.\n"]}],"source":["app = LLMServe()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T06:46:03.641138Z","iopub.status.busy":"2024-05-15T06:46:03.640772Z","iopub.status.idle":"2024-05-15T06:46:03.652400Z","shell.execute_reply":"2024-05-15T06:46:03.651480Z","shell.execute_reply.started":"2024-05-15T06:46:03.641108Z"},"trusted":true},"outputs":[],"source":["from typing import Union\n","from fastapi.middleware.cors import CORSMiddleware\n","from fastapi.responses import JSONResponse\n","from fastapi.encoders import jsonable_encoder\n","from fastapi import FastAPI\n","origins = [\"*\"]\n","app_api = FastAPI()\n","app_api.add_middleware(\n","    CORSMiddleware,\n","    allow_origins=origins,\n","    allow_credentials=True,\n","    allow_methods=[\"*\"],\n","    allow_headers=[\"*\"],\n",")\n","\n","@app_api.get(\"/\")\n","def read_root():\n","    return \"API RAG\"\n","\n","@app_api.get(\"/rag/{source}\")\n","async def read_item(source: str, q: str | None = None):\n","    if q:\n","        data = app.rag(source=source)(q)\n","        sources = []\n","        for docs in data[\"source_documents\"]:\n","            sources.append(docs.to_json()[\"kwargs\"])\n","        res = {\n","            \"result\" : data[\"result\"],\n","            \"source_documents\":sources\n","        }\n","        return JSONResponse(content=jsonable_encoder(res))\n","    return None\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T06:46:06.557777Z","iopub.status.busy":"2024-05-15T06:46:06.557393Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                                                                    \r"]},{"name":"stderr","output_type":"stream","text":["INFO:     Started server process [34]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"]},{"name":"stdout","output_type":"stream","text":["Public URL: https://ruling-plainly-jaguar.ngrok-free.app\n","INFO:     14.176.232.239:0 - \"OPTIONS /rag/vi-medical?q=Khi%20n%C3%A0o%20VNVC%20m%E1%BB%9Bi%20c%C3%B3%20d%E1%BB%8Bch%20v%E1%BB%A5%20ti%C3%AAm%20vaccine%20Covid-19?%20Gi%C3%A1%20kho%E1%BA%A3ng%20bao%20nhi%C3%AAu%20m%E1%BB%99t%20m%C5%A9i%20cho%20t%E1%BB%ABng%20lo%E1%BA%A1i%20AstraZeneca,%20Pfizer,%20v%C3%A0%20Moderna%20%E1%BA%A1? HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n","  warn_deprecated(\n","/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n","  warn_deprecated(\n","Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","/opt/conda/lib/python3.10/site-packages/optimum/bettertransformer/models/encoder_models.py:301: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n","  hidden_states = torch._nested_tensor_from_mask(hidden_states, ~attention_mask)\n","Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.38s/it]"]},{"name":"stdout","output_type":"stream","text":["INFO:     14.176.232.239:0 - \"GET /rag/vi-medical?q=Khi%20n%C3%A0o%20VNVC%20m%E1%BB%9Bi%20c%C3%B3%20d%E1%BB%8Bch%20v%E1%BB%A5%20ti%C3%AAm%20vaccine%20Covid-19?%20Gi%C3%A1%20kho%E1%BA%A3ng%20bao%20nhi%C3%AAu%20m%E1%BB%99t%20m%C5%A9i%20cho%20t%E1%BB%ABng%20lo%E1%BA%A1i%20AstraZeneca,%20Pfizer,%20v%C3%A0%20Moderna%20%E1%BA%A1? HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["INFO:     14.176.232.239:0 - \"OPTIONS /rag/vi-medical?q=Ph%C3%B2ng%20tr%C3%A1nh%20gan%20nhi%E1%BB%85m%20m%E1%BB%A1 HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.35s/it]"]},{"name":"stdout","output_type":"stream","text":["INFO:     14.176.232.239:0 - \"GET /rag/vi-medical?q=Ph%C3%B2ng%20tr%C3%A1nh%20gan%20nhi%E1%BB%85m%20m%E1%BB%A1 HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import nest_asyncio\n","from pyngrok import ngrok\n","import uvicorn\n","ngrok.set_auth_token(NGROK_TOKEN)\n","ngrok_tunnel = ngrok.connect(8000,domain=NGROK_STATIC_DOMAIN)\n","print('Public URL:', ngrok_tunnel.public_url)\n","nest_asyncio.apply()\n","uvicorn.run(app_api, port=8000)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
